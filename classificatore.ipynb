{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Dataset/Train/X_train_with_trq_margin.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trq_measured</th>\n",
       "      <th>oat</th>\n",
       "      <th>mgt</th>\n",
       "      <th>pa</th>\n",
       "      <th>ias</th>\n",
       "      <th>np</th>\n",
       "      <th>ng</th>\n",
       "      <th>trq_target</th>\n",
       "      <th>faulty</th>\n",
       "      <th>trq_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.690790</td>\n",
       "      <td>-0.165988</td>\n",
       "      <td>0.027987</td>\n",
       "      <td>-0.925711</td>\n",
       "      <td>0.810638</td>\n",
       "      <td>-1.045463</td>\n",
       "      <td>1.280369</td>\n",
       "      <td>0.800616</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.057098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.473188</td>\n",
       "      <td>0.313427</td>\n",
       "      <td>2.123784</td>\n",
       "      <td>-0.312016</td>\n",
       "      <td>0.913846</td>\n",
       "      <td>0.072721</td>\n",
       "      <td>1.263805</td>\n",
       "      <td>1.447255</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.115131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.466291</td>\n",
       "      <td>0.942660</td>\n",
       "      <td>-1.019912</td>\n",
       "      <td>-0.421774</td>\n",
       "      <td>0.312093</td>\n",
       "      <td>-2.094875</td>\n",
       "      <td>1.316260</td>\n",
       "      <td>-1.703897</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.465562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.334258</td>\n",
       "      <td>-0.106061</td>\n",
       "      <td>1.710670</td>\n",
       "      <td>-0.184317</td>\n",
       "      <td>1.130757</td>\n",
       "      <td>-0.067370</td>\n",
       "      <td>1.294173</td>\n",
       "      <td>1.334488</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.052871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.696288</td>\n",
       "      <td>1.435260</td>\n",
       "      <td>-0.177547</td>\n",
       "      <td>1.352120</td>\n",
       "      <td>-1.972702</td>\n",
       "      <td>0.526307</td>\n",
       "      <td>-0.842595</td>\n",
       "      <td>-0.648782</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.499112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598831</th>\n",
       "      <td>-0.120858</td>\n",
       "      <td>-1.484379</td>\n",
       "      <td>-0.503519</td>\n",
       "      <td>-0.503565</td>\n",
       "      <td>0.646206</td>\n",
       "      <td>-1.531962</td>\n",
       "      <td>1.244479</td>\n",
       "      <td>-0.128699</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.275479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598832</th>\n",
       "      <td>-0.427967</td>\n",
       "      <td>0.643025</td>\n",
       "      <td>0.186683</td>\n",
       "      <td>1.373404</td>\n",
       "      <td>-1.682088</td>\n",
       "      <td>0.717142</td>\n",
       "      <td>-0.577635</td>\n",
       "      <td>-0.392722</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.648192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598833</th>\n",
       "      <td>-0.413343</td>\n",
       "      <td>0.643025</td>\n",
       "      <td>0.199278</td>\n",
       "      <td>1.371820</td>\n",
       "      <td>-1.524653</td>\n",
       "      <td>0.536297</td>\n",
       "      <td>-0.522419</td>\n",
       "      <td>-0.450824</td>\n",
       "      <td>1</td>\n",
       "      <td>10.239773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598834</th>\n",
       "      <td>-3.159493</td>\n",
       "      <td>-0.571895</td>\n",
       "      <td>0.756841</td>\n",
       "      <td>0.577379</td>\n",
       "      <td>0.870825</td>\n",
       "      <td>0.586006</td>\n",
       "      <td>0.064906</td>\n",
       "      <td>-2.678510</td>\n",
       "      <td>1</td>\n",
       "      <td>3.016958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598835</th>\n",
       "      <td>-0.881320</td>\n",
       "      <td>0.882733</td>\n",
       "      <td>-0.443064</td>\n",
       "      <td>0.829363</td>\n",
       "      <td>-1.340978</td>\n",
       "      <td>0.607616</td>\n",
       "      <td>-1.080097</td>\n",
       "      <td>-0.877049</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.029433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598836 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trq_measured       oat       mgt        pa       ias        np  \\\n",
       "0           0.690790 -0.165988  0.027987 -0.925711  0.810638 -1.045463   \n",
       "1           1.473188  0.313427  2.123784 -0.312016  0.913846  0.072721   \n",
       "2          -1.466291  0.942660 -1.019912 -0.421774  0.312093 -2.094875   \n",
       "3           1.334258 -0.106061  1.710670 -0.184317  1.130757 -0.067370   \n",
       "4          -0.696288  1.435260 -0.177547  1.352120 -1.972702  0.526307   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "598831     -0.120858 -1.484379 -0.503519 -0.503565  0.646206 -1.531962   \n",
       "598832     -0.427967  0.643025  0.186683  1.373404 -1.682088  0.717142   \n",
       "598833     -0.413343  0.643025  0.199278  1.371820 -1.524653  0.536297   \n",
       "598834     -3.159493 -0.571895  0.756841  0.577379  0.870825  0.586006   \n",
       "598835     -0.881320  0.882733 -0.443064  0.829363 -1.340978  0.607616   \n",
       "\n",
       "              ng  trq_target  faulty  trq_margin  \n",
       "0       1.280369    0.800616       0   -3.057098  \n",
       "1       1.263805    1.447255       0   -2.115131  \n",
       "2       1.316260   -1.703897       0   -6.465562  \n",
       "3       1.294173    1.334488       0   -7.052871  \n",
       "4      -0.842595   -0.648782       0   -9.499112  \n",
       "...          ...         ...     ...         ...  \n",
       "598831  1.244479   -0.128699       1  -11.275479  \n",
       "598832 -0.577635   -0.392722       1   -0.648192  \n",
       "598833 -0.522419   -0.450824       1   10.239773  \n",
       "598834  0.064906   -2.678510       1    3.016958  \n",
       "598835 -1.080097   -0.877049       1   -1.029433  \n",
       "\n",
       "[598836 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Supponiamo che df sia il DataFrame contenente i dati, già preparati\n",
    "y = df['faulty'].values\n",
    "X = df.drop(columns=['trq_target', 'faulty'])\n",
    "\n",
    "# Divisione in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lista di classificatori da provare\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trq_measured</th>\n",
       "      <th>oat</th>\n",
       "      <th>mgt</th>\n",
       "      <th>pa</th>\n",
       "      <th>ias</th>\n",
       "      <th>np</th>\n",
       "      <th>ng</th>\n",
       "      <th>trq_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192115</th>\n",
       "      <td>0.983275</td>\n",
       "      <td>0.972623</td>\n",
       "      <td>1.191759</td>\n",
       "      <td>-1.035997</td>\n",
       "      <td>-1.687336</td>\n",
       "      <td>-0.373024</td>\n",
       "      <td>1.316260</td>\n",
       "      <td>0.080256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220666</th>\n",
       "      <td>1.897292</td>\n",
       "      <td>0.223537</td>\n",
       "      <td>1.448696</td>\n",
       "      <td>-0.496177</td>\n",
       "      <td>-0.875670</td>\n",
       "      <td>0.620352</td>\n",
       "      <td>0.399681</td>\n",
       "      <td>9.601690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93178</th>\n",
       "      <td>1.122206</td>\n",
       "      <td>-0.285841</td>\n",
       "      <td>0.267291</td>\n",
       "      <td>-0.206479</td>\n",
       "      <td>1.078278</td>\n",
       "      <td>0.615257</td>\n",
       "      <td>-0.105542</td>\n",
       "      <td>-4.153085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530359</th>\n",
       "      <td>-1.122620</td>\n",
       "      <td>0.283464</td>\n",
       "      <td>-1.004798</td>\n",
       "      <td>1.348074</td>\n",
       "      <td>-1.470425</td>\n",
       "      <td>0.630540</td>\n",
       "      <td>-1.292677</td>\n",
       "      <td>-4.950618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204582</th>\n",
       "      <td>0.515298</td>\n",
       "      <td>0.942660</td>\n",
       "      <td>0.365531</td>\n",
       "      <td>-0.086695</td>\n",
       "      <td>1.123760</td>\n",
       "      <td>0.653464</td>\n",
       "      <td>-0.218734</td>\n",
       "      <td>0.512488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110268</th>\n",
       "      <td>-0.318285</td>\n",
       "      <td>-0.285841</td>\n",
       "      <td>-1.009836</td>\n",
       "      <td>-0.078252</td>\n",
       "      <td>0.759909</td>\n",
       "      <td>0.587239</td>\n",
       "      <td>-1.309241</td>\n",
       "      <td>-1.570566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>-1.042187</td>\n",
       "      <td>-0.615439</td>\n",
       "      <td>-1.828506</td>\n",
       "      <td>-0.479819</td>\n",
       "      <td>-0.658759</td>\n",
       "      <td>-2.359775</td>\n",
       "      <td>1.225154</td>\n",
       "      <td>-4.354306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365838</th>\n",
       "      <td>1.868044</td>\n",
       "      <td>-3.641747</td>\n",
       "      <td>1.307632</td>\n",
       "      <td>-0.031816</td>\n",
       "      <td>1.305685</td>\n",
       "      <td>-0.620094</td>\n",
       "      <td>1.261044</td>\n",
       "      <td>-4.612870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>-0.822823</td>\n",
       "      <td>0.882733</td>\n",
       "      <td>-0.770532</td>\n",
       "      <td>-0.049757</td>\n",
       "      <td>-0.342139</td>\n",
       "      <td>0.599975</td>\n",
       "      <td>-1.251265</td>\n",
       "      <td>-6.588956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>0.178940</td>\n",
       "      <td>-0.675366</td>\n",
       "      <td>-0.984646</td>\n",
       "      <td>-0.388530</td>\n",
       "      <td>0.689938</td>\n",
       "      <td>0.617804</td>\n",
       "      <td>-1.060771</td>\n",
       "      <td>5.909664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479068 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trq_measured       oat       mgt        pa       ias        np  \\\n",
       "192115      0.983275  0.972623  1.191759 -1.035997 -1.687336 -0.373024   \n",
       "220666      1.897292  0.223537  1.448696 -0.496177 -0.875670  0.620352   \n",
       "93178       1.122206 -0.285841  0.267291 -0.206479  1.078278  0.615257   \n",
       "530359     -1.122620  0.283464 -1.004798  1.348074 -1.470425  0.630540   \n",
       "204582      0.515298  0.942660  0.365531 -0.086695  1.123760  0.653464   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "110268     -0.318285 -0.285841 -1.009836 -0.078252  0.759909  0.587239   \n",
       "259178     -1.042187 -0.615439 -1.828506 -0.479819 -0.658759 -2.359775   \n",
       "365838      1.868044 -3.641747  1.307632 -0.031816  1.305685 -0.620094   \n",
       "131932     -0.822823  0.882733 -0.770532 -0.049757 -0.342139  0.599975   \n",
       "121958      0.178940 -0.675366 -0.984646 -0.388530  0.689938  0.617804   \n",
       "\n",
       "              ng  trq_margin  \n",
       "192115  1.316260    0.080256  \n",
       "220666  0.399681    9.601690  \n",
       "93178  -0.105542   -4.153085  \n",
       "530359 -1.292677   -4.950618  \n",
       "204582 -0.218734    0.512488  \n",
       "...          ...         ...  \n",
       "110268 -1.309241   -1.570566  \n",
       "259178  1.225154   -4.354306  \n",
       "365838  1.261044   -4.612870  \n",
       "131932 -1.251265   -6.588956  \n",
       "121958 -1.060771    5.909664  \n",
       "\n",
       "[479068 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trq_measured</th>\n",
       "      <th>oat</th>\n",
       "      <th>mgt</th>\n",
       "      <th>pa</th>\n",
       "      <th>ias</th>\n",
       "      <th>np</th>\n",
       "      <th>ng</th>\n",
       "      <th>trq_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32072</th>\n",
       "      <td>1.443940</td>\n",
       "      <td>-0.195951</td>\n",
       "      <td>0.803835</td>\n",
       "      <td>-0.850252</td>\n",
       "      <td>1.003059</td>\n",
       "      <td>-0.561511</td>\n",
       "      <td>1.307977</td>\n",
       "      <td>-3.564409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353171</th>\n",
       "      <td>0.522210</td>\n",
       "      <td>0.738200</td>\n",
       "      <td>1.531429</td>\n",
       "      <td>2.052640</td>\n",
       "      <td>-1.517738</td>\n",
       "      <td>0.520339</td>\n",
       "      <td>0.244462</td>\n",
       "      <td>7.698460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448003</th>\n",
       "      <td>0.829720</td>\n",
       "      <td>-1.184745</td>\n",
       "      <td>0.272329</td>\n",
       "      <td>-0.710416</td>\n",
       "      <td>-1.968971</td>\n",
       "      <td>-0.856976</td>\n",
       "      <td>1.291413</td>\n",
       "      <td>-5.617264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162527</th>\n",
       "      <td>-0.471840</td>\n",
       "      <td>0.103683</td>\n",
       "      <td>-1.176089</td>\n",
       "      <td>-1.067658</td>\n",
       "      <td>-1.094330</td>\n",
       "      <td>-1.903841</td>\n",
       "      <td>1.307977</td>\n",
       "      <td>-6.783396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299628</th>\n",
       "      <td>0.032697</td>\n",
       "      <td>0.223537</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>0.395607</td>\n",
       "      <td>1.139503</td>\n",
       "      <td>0.671294</td>\n",
       "      <td>-0.572113</td>\n",
       "      <td>-5.455970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579892</th>\n",
       "      <td>1.136830</td>\n",
       "      <td>1.751673</td>\n",
       "      <td>1.937379</td>\n",
       "      <td>-0.399084</td>\n",
       "      <td>-1.173047</td>\n",
       "      <td>0.678935</td>\n",
       "      <td>0.573610</td>\n",
       "      <td>-8.198281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22247</th>\n",
       "      <td>0.119186</td>\n",
       "      <td>0.231972</td>\n",
       "      <td>-0.447943</td>\n",
       "      <td>-0.609955</td>\n",
       "      <td>-0.113475</td>\n",
       "      <td>0.579042</td>\n",
       "      <td>-0.806465</td>\n",
       "      <td>60.683974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142845</th>\n",
       "      <td>-0.464528</td>\n",
       "      <td>0.792842</td>\n",
       "      <td>-0.672291</td>\n",
       "      <td>-0.573219</td>\n",
       "      <td>-0.459340</td>\n",
       "      <td>0.610163</td>\n",
       "      <td>-1.281634</td>\n",
       "      <td>-14.897612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547565</th>\n",
       "      <td>-0.274412</td>\n",
       "      <td>-0.615439</td>\n",
       "      <td>-0.712595</td>\n",
       "      <td>0.747571</td>\n",
       "      <td>0.691687</td>\n",
       "      <td>0.681482</td>\n",
       "      <td>-1.016599</td>\n",
       "      <td>-13.725804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230561</th>\n",
       "      <td>-0.874008</td>\n",
       "      <td>0.133647</td>\n",
       "      <td>-1.468291</td>\n",
       "      <td>-0.976896</td>\n",
       "      <td>-0.034265</td>\n",
       "      <td>-2.059216</td>\n",
       "      <td>1.261044</td>\n",
       "      <td>18.672497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trq_measured       oat       mgt        pa       ias        np  \\\n",
       "32072       1.443940 -0.195951  0.803835 -0.850252  1.003059 -0.561511   \n",
       "353171      0.522210  0.738200  1.531429  2.052640 -1.517738  0.520339   \n",
       "448003      0.829720 -1.184745  0.272329 -0.710416 -1.968971 -0.856976   \n",
       "162527     -0.471840  0.103683 -1.176089 -1.067658 -1.094330 -1.903841   \n",
       "299628      0.032697  0.223537  0.020430  0.395607  1.139503  0.671294   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "579892      1.136830  1.751673  1.937379 -0.399084 -1.173047  0.678935   \n",
       "22247       0.119186  0.231972 -0.447943 -0.609955 -0.113475  0.579042   \n",
       "142845     -0.464528  0.792842 -0.672291 -0.573219 -0.459340  0.610163   \n",
       "547565     -0.274412 -0.615439 -0.712595  0.747571  0.691687  0.681482   \n",
       "230561     -0.874008  0.133647 -1.468291 -0.976896 -0.034265 -2.059216   \n",
       "\n",
       "              ng  trq_margin  \n",
       "32072   1.307977   -3.564409  \n",
       "353171  0.244462    7.698460  \n",
       "448003  1.291413   -5.617264  \n",
       "162527  1.307977   -6.783396  \n",
       "299628 -0.572113   -5.455970  \n",
       "...          ...         ...  \n",
       "579892  0.573610   -8.198281  \n",
       "22247  -0.806465   60.683974  \n",
       "142845 -1.281634  -14.897612  \n",
       "547565 -1.016599  -13.725804  \n",
       "230561  1.261044   18.672497  \n",
       "\n",
       "[119768 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauraferretti/.venvs/textToSpeech/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9136664217487142\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91     59747\n",
      "           1       0.92      0.91      0.91     60021\n",
      "\n",
      "    accuracy                           0.91    119768\n",
      "   macro avg       0.91      0.91      0.91    119768\n",
      "weighted avg       0.91      0.91      0.91    119768\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9989646650190368\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     59747\n",
      "           1       1.00      1.00      1.00     60021\n",
      "\n",
      "    accuracy                           1.00    119768\n",
      "   macro avg       1.00      1.00      1.00    119768\n",
      "weighted avg       1.00      1.00      1.00    119768\n",
      "\n",
      "==================================================\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.9651242401977156\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     59747\n",
      "           1       0.96      0.97      0.97     60021\n",
      "\n",
      "    accuracy                           0.97    119768\n",
      "   macro avg       0.97      0.97      0.97    119768\n",
      "weighted avg       0.97      0.97      0.97    119768\n",
      "\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.9614087235321622\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     59747\n",
      "           1       0.96      0.96      0.96     60021\n",
      "\n",
      "    accuracy                           0.96    119768\n",
      "   macro avg       0.96      0.96      0.96    119768\n",
      "weighted avg       0.96      0.96      0.96    119768\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauraferretti/.venvs/textToSpeech/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lauraferretti/.venvs/textToSpeech/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lauraferretti/.venvs/textToSpeech/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lauraferretti/.venvs/textToSpeech/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lauraferretti/.venvs/textToSpeech/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - CV Accuracy: 0.9089 ± 0.0049\n",
      "Random Forest - CV Accuracy: 0.9991 ± 0.0001\n",
      "K-Nearest Neighbors - CV Accuracy: 0.9676 ± 0.0007\n",
      "Gradient Boosting - CV Accuracy: 0.9609 ± 0.0006\n"
     ]
    }
   ],
   "source": [
    "# Valutazione dei modelli\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Addestramento del classificatore\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predizione\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Salvo i risultati\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Se vuoi confrontare anche la validazione incrociata\n",
    "for name, clf in classifiers.items():\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=5)  # 5-fold cross-validation\n",
    "    print(f\"{name} - CV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textToSpeech",
   "language": "python",
   "name": "texttospeech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
