{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial regression for trq_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio dell'addestramento del modello di regressione lineare...\n",
      "Mean Squared Error: 0.6378179402391422\n",
      "R^2: 0.5021571017282549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Caricamento dei dati da CSV\n",
    "X_train_target = pd.read_csv('Dataset/Train/X_train_resampled_with_target.csv')\n",
    "\n",
    "# 2. Selezioniamo solo la colonna 'trq_target' come target\n",
    "y = X_train_target['trq_target'].values\n",
    "\n",
    "# 3. Creiamo la matrice delle caratteristiche (escludiamo 'trq_measured')\n",
    "X = X_train_target.drop(columns=['trq_measured', 'trq_target'])\n",
    "\n",
    "# 4. Suddivisione dei dati in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Creazione del modello di regressione lineare\n",
    "model = LinearRegression()\n",
    "\n",
    "# 6. Addestramento del modello\n",
    "print(\"Inizio dell'addestramento del modello di regressione lineare...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predizione\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 8. Valutazione\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Caricamento dei dati\n",
    "X_train_target = pd.read_csv('Dataset/Train/X_train_resampled_with_target.csv')\n",
    "\n",
    "# Selezioniamo la variabile target e le feature\n",
    "y = X_train_target['trq_target']\n",
    "X = X_train_target.drop(columns=['trq_measured', 'trq_target'])\n",
    "\n",
    "# Suddividiamo il dataset in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Migliori parametri per la Regressione Lineare: {'fit_intercept': False}\n",
      "Mean Squared Error per la Regressione Lineare: 0.6378162318363662\n",
      "R^2 per la Regressione Lineare: 0.502158435206252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parametri per la Regressione Lineare\n",
    "lr_param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Inizializzazione del modello\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Eseguiamo la GridSearch\n",
    "grid_search_lr = GridSearchCV(estimator=lr_model, param_grid=lr_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per la Regressione Lineare: {grid_search_lr.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "y_pred_lr = best_lr_model.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f'Mean Squared Error per la Regressione Lineare: {mse_lr}')\n",
    "print(f'R^2 per la Regressione Lineare: {r2_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Migliori parametri per il Decision Tree Regressor: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Mean Squared Error per il Decision Tree Regressor: 0.21345672434772667\n",
      "R^2 per il Decision Tree Regressor: 0.833388326667291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parametri per il Decision Tree Regressor\n",
    "dt_param_grid = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Inizializzazione del modello\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Eseguiamo la GridSearch\n",
    "grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=dt_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per il Decision Tree Regressor: {grid_search_dt.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_dt_model = grid_search_dt.best_estimator_\n",
    "y_pred_dt = best_dt_model.predict(X_test)\n",
    "\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f'Mean Squared Error per il Decision Tree Regressor: {mse_dt}')\n",
    "print(f'R^2 per il Decision Tree Regressor: {r2_dt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Eseguiamo la GridSearch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model, param_grid\u001b[38;5;241m=\u001b[39mrf_param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Visualizza i migliori parametri trovati\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMigliori parametri per il Random Forest Regressor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search_rf\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parametri per il Random Forest Regressor\n",
    "rf_param_grid = {\n",
    "    #'n_estimators': [100, 200, 300],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Inizializzazione del modello\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Eseguiamo la GridSearch\n",
    "#grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per il Random Forest Regressor: {grid_search_rf.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Mean Squared Error per il Random Forest Regressor: {mse_rf}')\n",
    "print(f'R^2 per il Random Forest Regressor: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Eseguiamo la GridSearch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model, param_grid\u001b[38;5;241m=\u001b[39mrf_param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Visualizza i migliori parametri trovati\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMigliori parametri per il Random Forest Regressor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search_rf\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gians_ji5genm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parametri per il Random Forest Regressor\n",
    "rf_param_grid = {\n",
    "    #'n_estimators': [100, 200, 300],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Inizializzazione del modello\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Eseguiamo la GridSearch\n",
    "#grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per il Random Forest Regressor: {grid_search_rf.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Mean Squared Error per il Random Forest Regressor: {mse_rf}')\n",
    "print(f'R^2 per il Random Forest Regressor: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Parametri per il Random Forest Regressor\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],  # None significa che non viene imposta alcuna profondit√† massima\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Inizializzazione del modello\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Eseguiamo la RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_distributions=rf_param_dist, \n",
    "    n_iter=50,  # Numero di combinazioni casuali da esplorare\n",
    "    cv=3, \n",
    "    n_jobs=-1,  # Utilizza tutti i core disponibili\n",
    "    verbose=2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Esegui la RandomizedSearchCV\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per il Random Forest Regressor: {random_search_rf.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Mean Squared Error per il Random Forest Regressor: {mse_rf}')\n",
    "print(f'R^2 per il Random Forest Regressor: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Migliori parametri per l'XGBoost Regressor: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Mean Squared Error per l'XGBoost Regressor: 0.17326962140503294\n",
      "R^2 per l'XGBoost Regressor: 0.864755998443087\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parametri per l'XGBoost Regressor\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Inizializzazione del modello\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# Eseguiamo la GridSearch\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per l'XGBoost Regressor: {grid_search_xgb.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'Mean Squared Error per l\\'XGBoost Regressor: {mse_xgb}')\n",
    "print(f'R^2 per l\\'XGBoost Regressor: {r2_xgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Migliori parametri per il Regressore Polinomiale: {'linearregression__fit_intercept': True, 'polynomialfeatures__degree': 4}\n",
      "Mean Squared Error per il Regressore Polinomiale: 0.33835936739139727\n",
      "R^2 per il Regressore Polinomiale: 0.7358967230423635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parametri per il Polynomial Regressor\n",
    "poly_param_grid = {\n",
    "    'polynomialfeatures__degree': [2, 3, 4],  # Grado del polinomio\n",
    "    'linearregression__fit_intercept': [True, False],  # Se includere l'intercetta nel modello\n",
    "}\n",
    "\n",
    "# Creiamo un modello che include il PolynomialFeatures seguito dalla Regressione Lineare\n",
    "poly_model = make_pipeline(\n",
    "    PolynomialFeatures(),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# Eseguiamo la GridSearch\n",
    "grid_search_poly = GridSearchCV(estimator=poly_model, param_grid=poly_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_poly.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza i migliori parametri trovati\n",
    "print(f\"Migliori parametri per il Regressore Polinomiale: {grid_search_poly.best_params_}\")\n",
    "\n",
    "# Predizione e valutazione\n",
    "best_poly_model = grid_search_poly.best_estimator_\n",
    "y_pred_poly = best_poly_model.predict(X_test)\n",
    "\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "print(f'Mean Squared Error per il Regressore Polinomiale: {mse_poly}')\n",
    "print(f'R^2 per il Regressore Polinomiale: {r2_poly}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio dell'addestramento del modello Random Forest...\n",
      "Mean Squared Error: 0.18304701080264646\n",
      "R^2: 0.8571243475155288\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Caricamento dei dati\n",
    "X_train_target = pd.read_csv('Dataset/Train/X_train_resampled_with_target.csv')\n",
    "\n",
    "# Selezioniamo la variabile target e le feature\n",
    "y = X_train_target['trq_target']\n",
    "X = X_train_target.drop(columns=['trq_measured', 'trq_target'])\n",
    "\n",
    "# Suddividiamo il dataset in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creazione del modello Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Addestramento del modello\n",
    "print(\"Inizio dell'addestramento del modello Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predizione sui dati di test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calcolo degli errori\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2: {r2}')\n",
    "\n",
    "# Visualizzazione della feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "feature_importance = rf_model.feature_importances_\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(indices)), feature_importance[indices], align='center')\n",
    "plt.yticks(range(len(indices)), [X.columns[i] for i in indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Importanza delle Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio dell'addestramento del modello SVR...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Addestramento del modello\n",
    "print(\"Inizio dell'addestramento del modello SVR...\")\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predizione sui dati di testt\n",
    "y_pred_scaled = svr_model.predict(X_test)\n",
    "\n",
    "# Calcolo degli errori\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2: {r2}')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "plt.xlabel('Valori Reali')\n",
    "plt.ylabel('Valori Predetti')\n",
    "plt.title('Support Vector Regression: Valori Reali vs Predetti')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
